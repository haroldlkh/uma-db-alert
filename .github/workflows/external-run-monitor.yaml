name: Run external UMA Monitor (reusable)

on:
  workflow_call:
    inputs:
      dry_run:            { type: boolean, default: false }
      sites_path:         { type: string,  required: false }       # path inside CALLER repo
      reset_state:        { type: boolean, default: false }
      outputs_profiles:   { type: string,  required: false, default: "discord_forum" }
      tool_ref:           { type: string,  required: false, default: "main" }  # tag/branch of YOUR repo
      prune_caches:       { type: boolean, default: true }         # keep newest 3
    secrets:
      CALLER_DISCORD_WEBHOOK_FORUM: { required: false }

jobs:
  run:
    if: ${{ github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && vars.RUN_MONITOR == 'true') }}
    runs-on: ubuntu-latest

    env:
      # Only expose what selected outputs require; preflight enforces presence
      DISCORD_WEBHOOK_FORUM: ${{ secrets.CALLER_DISCORD_WEBHOOK_FORUM }}

    steps:
      # 1) Caller repo (their sites.yaml usually lives here)
      - uses: actions/checkout@v4

      # 2) Your tool repo (code + catalogue), pinned by input
      - name: Checkout UMA tool repo
        uses: actions/checkout@v4
        with:
          repository: haroldlkh/uma-db-alert
          ref: ${{ inputs.tool_ref }}
          path: _tool

      # 3) Install deps from YOUR repo
      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r _tool/requirements.txt

      # 4) Prepare sites config (prefer caller path; else caller default; else tool sample)
      - name: Prepare sites config (path > caller default > tool sample)
        id: cfg
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${{ inputs.sites_path }}" ] && [ -f "${{ inputs.sites_path }}" ]; then
            cp "${{ inputs.sites_path }}" sites.effective.yaml
          elif [ -f "config/sites.yaml" ]; then
            cp "config/sites.yaml" sites.effective.yaml
          else
            cp "_tool/config/sites.yaml" sites.effective.yaml
          fi
          echo "sites=sites.effective.yaml" >> "$GITHUB_OUTPUT"

      # ---------- STATE CACHE ----------
      - name: Resolve state dir (per repo + environment)
        id: st
        shell: bash
        run: |
          REPO_NS="${GITHUB_REPOSITORY//\//_}"
          ENV_NAME="${{ inputs.environment_name }}"
          DIR="$HOME/.uma_monitor/$REPO_NS/$ENV_NAME"
          echo "dir=$DIR" >> "$GITHUB_OUTPUT"
          mkdir -p "$DIR"

      - name: Restore state cache
        uses: actions/cache/restore@v4
        with:
          path: ${{ steps.st.outputs.dir }}
          key: uma-state-${{ github.repository }}-${{ inputs.environment_name }}-v1-${{ github.run_id }}
          restore-keys: |
            uma-state-${{ github.repository }}-${{ inputs.environment_name }}-v1-

      - name: Reset state dir (toggle)
        if: ${{ inputs.reset_state }}
        run: rm -rf ~/.uma_monitor

      - name: Set state namespace env
        run: |
          echo "UMA_ENV_NAME=${{ inputs.environment_name }}" >> $GITHUB_ENV
          echo "UMA_STATE_DIR=${{ steps.st.outputs.dir }}" >> $GITHUB_ENV
      # ----------------------------------

      # 5) Playwright cache/install
      - name: Cache Playwright browsers (optional)
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-msplaywright-${{ hashFiles('_tool/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-msplaywright-

      - name: Install Playwright browsers (Chromium)
        run: python -m playwright install chromium

      # 6) Build outputs.effective.yaml from YOUR catalogue
      - name: Resolve outputs profiles â†’ outputs.effective.yaml
        run: |
          python - <<'PY'
          import sys, yaml, os
          csv = os.environ.get("INPUTS", "discord_forum")
          names = [n.strip() for n in csv.split(",") if n.strip()]
          with open("_tool/config/output_catalogue.yaml", "r", encoding="utf-8") as f:
              catalogue = yaml.safe_load(f) or {}
          table = catalogue.get("outputs", {}) or {}
          chosen, missing = [], []
          for n in names:
              spec = table.get(n)
              (chosen if spec else missing).append(n if not spec else spec)
          if missing:
              sys.stderr.write("Unknown outputs profile(s): " + ", ".join(missing) + "\n")
              sys.exit(1)
          if not chosen:
              sys.stderr.write("No outputs selected.\n"); sys.exit(1)
          with open("outputs.effective.yaml", "w", encoding="utf-8") as g:
              yaml.safe_dump({"outputs": chosen}, g, allow_unicode=True, sort_keys=False)
          print(f"Using outputs: {', '.join(names)}")
          PY
        env:
          INPUTS: ${{ inputs.outputs_profiles }}

      # 7) Preflight envs required by selected outputs
      - name: Preflight required webhooks
        shell: bash
        run: |
          set -euo pipefail
          reqs="$(python - <<'PY'
          import yaml
          d = yaml.safe_load(open("outputs.effective.yaml","r",encoding="utf-8")) or {}
          names = []
          for o in d.get("outputs", []):
              env = (o.get("settings") or {}).get("webhook_env")
              if env: names.append(env)
          print(" ".join(sorted(set(names))))
          PY
          )"
          missing=0
          for name in $reqs; do
            if [ -z "${!name:-}" ]; then
              echo "::error::Required env $name is not set (selected by outputs_profiles)"
              missing=1
            fi
          done
          [ "$missing" -eq 0 ]

      # 8) Run orchestrator from YOUR repo
      - name: Run orchestrator
        env:
          PYTHONPATH: ${{ github.workspace }}/_tool
        run: |
          DRY=""
          if [ "${{ inputs.dry_run }}" = "true" ]; then DRY="--dry-run"; fi
          python _tool/orchestrator.py \
            --sites "${{ steps.cfg.outputs.sites }}" \
            --outputs outputs.effective.yaml \
            $DRY

      # 9) Save updated state cache
      - name: Save state cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: ${{ steps.st.outputs.dir }}
          key: uma-state-${{ github.repository }}-${{ inputs.environment_name }}-v1-${{ github.run_id }}

      # 10) (Optional) prune: keep newest 3; skips silently if no permission
      - name: Prune old UMA state caches (keep last 3)
        if: always()
        env:
          GH_TOKEN: ${{ github.token }}
          REPO: ${{ github.repository }}
          ENV:  ${{ inputs.environment_name }}
        run: |
          set -euo pipefail
          PREFIX="uma-state-${REPO}-${ENV}-v1-"
          # List caches (first 100 is plenty in practice), sort newest-first, drop first 3, delete the rest
          gh api -H "Accept: application/vnd.githubjson" "/repos/${REPO}/actions/caches?per_page=100" \
            --jq ".actions_caches
                 | map(select(.key | startswith(\"${PREFIX}\")))
                 | sort_by(.last_accessed_at) | reverse | .[3:] | .[].id" \
          | while read -r ID; do
              echo "Deleting cache id=$ID"
              gh api -X DELETE "/repos/${REPO}/actions/caches/${ID}"
            done
